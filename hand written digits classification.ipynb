{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/8b/c8887d5cfcb5b6d6193da48defe365d5c9522d47fdb96cbc8cdf3e1528b8/opencv_python-4.5.2.52-cp37-cp37m-win_amd64.whl (34.7MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\deepak\\anaconda3\\lib\\site-packages (from opencv-python) (1.15.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.2.52\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Image.open(r'C:\\Users\\Deepak\\Downloads\\name.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABoklEQVR4nHXTTUvUURjG4evvzKjjS5aMvRCpoVYiFBgRguEiKaJFEC2CIOgDtGlXK/ct6wsUbSJaZJsgCislCNIiC4Qis8BMNMVssHROi5HxTNS9Otw/znOet5ME/1c6Oufnl0NNY+2/4Nu7TyeXCnWt/WfbSl4oauVaM0lXd4bOe+teWIeFq5UkF2cWBlLseFwOnzdhz6cQZrvRN190K4rBb83i8C5yRzDyoOgW4dww7EuwH6uDaxGcmYat0FyNl18j+COPJAu5LKYnI5hUQIC6GvyciuCWWoRFqK5CIQ67rRXeQzoN8xGsPw7Dc0ilIR9B5zrx6vpS4fdCAdbKent/J6p6z5zoysCluH0hPDu5CeQq4UoIIYTSyHpvvx79sta4t+HCZ+TKwpb0rgmpO3HjN/RtGQ1tcbaF/Oo6/JhH++4Yvjl1Yx2OBRzbHL85VHH6dwghhLmD2D5WNuwkM/EdPBrH+QPim0+y9Q9DCOHDIRydLt+hoayOy4MjN3vQP/HX9r1oSZPKkukYmCnVnBS/w8r46PjU4q9sS09f+0bNfwD22ANx1qkH7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x24F07472EF0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpydata = asarray(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 246, 228,\n",
       "        217, 216, 226, 244, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 212, 129,  67,  35,\n",
       "         22,  20,  32,  64, 132, 220, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 249, 147,  30,   0,   0,   1,\n",
       "         43,  50,   5,   0,   0,  41, 177, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 254, 139,   6,   0,   0,   1, 109,\n",
       "        233, 240, 128,   3,   0,   0,  25, 190, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 199,  21,   0,   0,   0,  38, 225,\n",
       "        255, 255, 235,  50,   0,   0,   0,  63, 238, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 107,   0,   0,   0,   0,  93, 254,\n",
       "        255, 255, 255, 111,   0,   0,   0,   4, 166, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 236,  47,   0,   0,   0,   0, 133, 255,\n",
       "        255, 255, 255, 157,   0,   0,   0,   0,  88, 252, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 213,  22,   0,   0,   0,   0, 155, 255,\n",
       "        255, 255, 255, 187,   8,   0,   0,   0,  37, 228, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 201,  13,   0,   0,   0,   1, 164, 255,\n",
       "        255, 255, 255, 207,  17,   0,   0,   0,  12, 196, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 202,  15,   0,   0,   0,   1, 163, 255,\n",
       "        255, 255, 255, 219,  27,   0,   0,   0,   2, 166, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 219,  26,   0,   0,   0,   0, 148, 255,\n",
       "        255, 255, 255, 227,  34,   0,   0,   0,   0, 142, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 242,  58,   0,   0,   0,   0, 112, 255,\n",
       "        255, 255, 255, 231,  38,   0,   0,   0,   0, 124, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 129,   0,   0,   0,   0,  52, 236,\n",
       "        255, 255, 255, 234,  42,   0,   0,   0,   0, 115, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 220,  41,   0,   0,   0,   4, 128,\n",
       "        242, 253, 250, 218,  40,   0,   0,   0,   0, 112, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 179,  27,   0,   0,   0,   7,\n",
       "         60,  84,  73,  43,   5,   0,   0,   0,   0, 114, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 195,  75,  14,   0,   0,\n",
       "          0,   0,   0,  20,   6,   0,   0,   0,   0, 122, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 244, 197, 147, 119,\n",
       "        116, 134, 173, 188,  29,   0,   0,   0,   0, 142, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 214,  21,   0,   0,   0,   3, 171, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 192,  10,   0,   0,   0,  18, 206, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 253, 246, 251, 255, 255, 255, 255,\n",
       "        255, 255, 255, 159,   1,   0,   0,   0,  54, 239, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 208,  69, 156, 255, 255, 255, 255,\n",
       "        255, 255, 255, 110,   0,   0,   0,   0, 124, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 192,   2,  82, 251, 255, 255, 255,\n",
       "        255, 255, 237,  51,   0,   0,   0,  24, 207, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 193,   7,  43, 234, 255, 255, 255,\n",
       "        255, 255, 170,   7,   0,   0,   0, 118, 254, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 193,   9,  13, 187, 255, 255, 255,\n",
       "        255, 221,  53,   0,   0,   0,  67, 231, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 192,   9,   0,  37, 121, 178, 197,\n",
       "        162,  57,   0,   0,   0,  68, 217, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 202,  31,   4,   0,   0,   3,   9,\n",
       "          0,   0,   5,  37, 128, 233, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255],\n",
       "       [255, 255, 255, 255, 255, 255, 248, 204, 154, 110,  80,  65,  59,\n",
       "         68,  99, 156, 219, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "#x is image, y is its label. every image in mnist dataset has label.\n",
    "#mnist.load_data() split 70%of data for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[45])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,\n",
       "        185, 255, 253, 253, 230, 132, 132,  31,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  71, 242,\n",
       "        252, 252, 228, 231, 252, 252, 252, 167,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  28, 166, 252, 252,\n",
       "        235,  92,   0,  14, 142, 252, 252, 150,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  12, 204, 252, 234, 152,\n",
       "         44,   0,   0,  48, 225, 252, 180,  16,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  12, 164, 252, 232,  61,   0,\n",
       "          0,   0,   6, 179, 252, 252,  60,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 252, 252,  76,   0,   0,\n",
       "          0,  44, 199, 252, 252, 252,  60,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  89, 252, 228,  32,   0,   0,\n",
       "         99, 231, 244, 220, 252, 203,  12,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 169, 252, 207,  97,  97, 206,\n",
       "        234, 243,  32, 157, 252, 145,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  60, 252, 252, 252, 252, 252,\n",
       "        200,  22,  11, 198, 231,  41,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  26, 131, 224, 252, 252, 142,\n",
       "         11,   0,  82, 252, 204,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  13, 253, 253, 141,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  82, 252, 220,  36,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 208, 252,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         24, 253, 247,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        121, 253, 199,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  32,\n",
       "        216, 244,  26,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 207,\n",
       "        252, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  33, 200, 249,\n",
       "        252,  92,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 252, 252,\n",
       "        142,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 252, 200,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01586433, 0.27021441, 0.34195734,\n",
       "        0.35243127, 0.35122598, 0.30807664, 0.20900864, 0.30757952,\n",
       "        0.13646196, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01633071, 0.10821775, 0.34901527, 0.36807584, 0.33793431,\n",
       "        0.31760605, 0.32068459, 0.33754484, 0.39901649, 0.58719726,\n",
       "        0.73513377, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.04554676,\n",
       "        0.3012109 , 0.38409681, 0.36343739, 0.34324533, 0.12337285,\n",
       "        0.        , 0.01943543, 0.19020384, 0.39901649, 0.58719726,\n",
       "        0.66029979, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0219743 , 0.3318407 ,\n",
       "        0.45725991, 0.35666132, 0.2192162 , 0.06426721, 0.        ,\n",
       "        0.        , 0.06663576, 0.30137932, 0.39901649, 0.41942662,\n",
       "        0.07043198, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.05766632, 0.30031543, 0.40992087,\n",
       "        0.42096944, 0.09297581, 0.        , 0.        , 0.        ,\n",
       "        0.00835805, 0.24849585, 0.33754484, 0.39901649, 0.13980887,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.23547082, 0.4614603 , 0.40992087,\n",
       "        0.13790378, 0.        , 0.        , 0.        , 0.0590044 ,\n",
       "        0.27720879, 0.34983774, 0.33754484, 0.39901649, 0.13980887,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.42769189, 0.4614603 , 0.37088079,\n",
       "        0.05806475, 0.        , 0.        , 0.14460122, 0.30977312,\n",
       "        0.33989419, 0.3054139 , 0.33754484, 0.32142995, 0.02796177,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.81213404, 0.4614603 , 0.33672071,\n",
       "        0.17600878, 0.14784679, 0.29709564, 0.34178471, 0.32586523,\n",
       "        0.04457629, 0.21795446, 0.33754484, 0.22959282, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.28833161, 0.4614603 , 0.40992087,\n",
       "        0.45725991, 0.38409681, 0.36343739, 0.29212368, 0.0295022 ,\n",
       "        0.0153231 , 0.27487251, 0.3094161 , 0.06491935, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1249437 , 0.23988611, 0.36437411,\n",
       "        0.45725991, 0.38409681, 0.20479408, 0.0160668 , 0.        ,\n",
       "        0.11422674, 0.34983774, 0.27325058, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01743312,\n",
       "        0.35243127, 0.35122598, 0.18886437, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.10996275,\n",
       "        0.35103826, 0.3054139 , 0.04822069, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.27892991,\n",
       "        0.35103826, 0.13327152, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03505484, 0.33927532,\n",
       "        0.34407322, 0.10828311, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.17673483, 0.33927532,\n",
       "        0.27720879, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04615078, 0.31549358, 0.32720624,\n",
       "        0.03621823, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.29853785, 0.36807584, 0.32318321,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.05987927, 0.30483874, 0.35911075, 0.36807584, 0.12337285,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15423449, 0.38409681, 0.36343739, 0.20740781, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15423449, 0.38409681, 0.28844237, 0.0160668 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Deepak\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))#since multiple outpus we use softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 188us/sample - loss: 0.2635 - acc: 0.9233\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 152us/sample - loss: 0.1087 - acc: 0.9661\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.0744 - acc: 0.9770\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 157us/sample - loss: 0.0552 - acc: 0.9823\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0411 - acc: 0.9866\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 0.0328 - acc: 0.9893\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 0.0261 - acc: 0.9915\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 159us/sample - loss: 0.0236 - acc: 0.9919\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 151us/sample - loss: 0.0177 - acc: 0.9940\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.0170 - acc: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f60ddc208>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.1252 - acc: 0.9718\n"
     ]
    }
   ],
   "source": [
    "val_loss,acc=model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12523967682738074"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9718"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\Deepak\\Untitled Folder\\digit_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Deepak\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Deepak\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "new_model=tf.keras.models.load_model(r'C:\\Users\\Deepak\\Untitled Folder\\digit_model.model')\n",
    "predictions=new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.85181106e-17, 6.70496861e-12, 5.05317684e-13, ...,\n",
       "        1.00000000e+00, 1.09942950e-15, 3.96702723e-12],\n",
       "       [2.47727888e-17, 3.04062664e-09, 1.00000000e+00, ...,\n",
       "        2.79107759e-16, 2.33197386e-13, 1.03542569e-23],\n",
       "       [2.88663815e-10, 9.99999046e-01, 3.54174148e-08, ...,\n",
       "        7.84843735e-07, 1.69195374e-07, 5.49075396e-10],\n",
       "       ...,\n",
       "       [3.84161682e-16, 6.53419124e-11, 1.55002424e-15, ...,\n",
       "        1.00469135e-08, 6.53991805e-10, 9.44269885e-10],\n",
       "       [6.38915743e-12, 2.65440420e-13, 1.15340333e-12, ...,\n",
       "        5.04264599e-12, 3.00868774e-10, 1.36701903e-17],\n",
       "       [1.02295852e-12, 9.98357183e-16, 1.09388283e-14, ...,\n",
       "        4.01454843e-19, 5.52446848e-14, 4.66567519e-17]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[145])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[145])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.10699626, 0.12179879, 0.1820581 ,\n",
       "        0.30961928, 0.23002506, 0.11334085, 0.05883493, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01145629,\n",
       "        0.06118522, 0.22470334, 0.31712145, 0.33862741, 0.32210279,\n",
       "        0.30719089, 0.30629652, 0.31511248, 0.2588737 , 0.19137952,\n",
       "        0.02185998, 0.00474644, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09215107, 0.15719579, 0.22657995,\n",
       "        0.3159155 , 0.31583303, 0.32614523, 0.33862741, 0.32210279,\n",
       "        0.30719089, 0.30629652, 0.31511248, 0.29770475, 0.31440922,\n",
       "        0.32532801, 0.19935037, 0.09750383, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2143514 , 0.37168724, 0.32204902,\n",
       "        0.3159155 , 0.31583303, 0.28747188, 0.29445861, 0.28008938,\n",
       "        0.26712251, 0.2663448 , 0.30514845, 0.29770475, 0.31440922,\n",
       "        0.32532801, 0.40028289, 0.2296757 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2143514 , 0.25415768, 0.32204902,\n",
       "        0.28594723, 0.16103739, 0.01546934, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13700543, 0.29770475, 0.31440922,\n",
       "        0.32532801, 0.40028289, 0.2296757 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.03405583, 0.02056767, 0.05091684,\n",
       "        0.03995769, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07099372, 0.29770475, 0.31440922,\n",
       "        0.32532801, 0.38287928, 0.18417391, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00607097, 0.16828149, 0.27899287, 0.29770475, 0.31440922,\n",
       "        0.32532801, 0.16612531, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08275368,\n",
       "        0.2161264 , 0.30629652, 0.31511248, 0.29770475, 0.31440922,\n",
       "        0.28160804, 0.0379715 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.12982948, 0.31828339,\n",
       "        0.30719089, 0.30629652, 0.31511248, 0.29770475, 0.15782597,\n",
       "        0.06043643, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05742419, 0.16113895, 0.33461206, 0.32210279,\n",
       "        0.30719089, 0.30629652, 0.30514845, 0.20121546, 0.0410099 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00636461,\n",
       "        0.05119579, 0.27089236, 0.32614523, 0.33862741, 0.31828339,\n",
       "        0.29747734, 0.29661126, 0.14323294, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.15784221,\n",
       "        0.3159155 , 0.31583303, 0.32614523, 0.25698206, 0.13367902,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02203612, 0.06904862, 0.28004263,\n",
       "        0.3159155 , 0.31583303, 0.24235298, 0.03346121, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2143514 , 0.37168724, 0.32204902,\n",
       "        0.3159155 , 0.23593851, 0.01675845, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15241952, 0.45073892, 0.37168724, 0.32204902,\n",
       "        0.23225409, 0.02746374, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.03861062, 0.04942134, 0.21623401,\n",
       "        0.2636057 , 0.32433989, 0.44418413, 0.78131889, 1.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.9701425 , 0.81042572, 0.50683087, 0.37168724, 0.32204902,\n",
       "        0.18730168, 0.07365276, 0.        , 0.        , 0.16296109,\n",
       "        0.15905931, 0.15859622, 0.27650186, 0.29770475, 0.31440922,\n",
       "        0.32532801, 0.40028289, 0.54818822, 0.38053873, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24253563, 0.56506748, 0.50683087, 0.37168724, 0.32204902,\n",
       "        0.3159155 , 0.29461105, 0.28618277, 0.29713551, 0.32082965,\n",
       "        0.30719089, 0.30629652, 0.31511248, 0.29770475, 0.31440922,\n",
       "        0.32532801, 0.40028289, 0.54818822, 0.4938907 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02602284, 0.33454844, 0.37168724, 0.32204902,\n",
       "        0.3159155 , 0.31583303, 0.32614523, 0.33862741, 0.32210279,\n",
       "        0.30719089, 0.30629652, 0.31511248, 0.29770475, 0.31440922,\n",
       "        0.32532801, 0.19618608, 0.2296757 , 0.02833799, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15224959, 0.27619447, 0.32204902,\n",
       "        0.3159155 , 0.31583303, 0.32614523, 0.33862741, 0.32210279,\n",
       "        0.30719089, 0.27118743, 0.07099372, 0.01765048, 0.01864086,\n",
       "        0.01928822, 0.00316429, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01762943, 0.11328997,\n",
       "        0.15109002, 0.31583303, 0.32614523, 0.20210569, 0.11330889,\n",
       "        0.1080632 , 0.0665862 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [28,28], In[1]: [784,128]\n\t [[{{node sequential_1/dense/MatMul}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-ce9eccb38cdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m           callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [28,28], In[1]: [784,128]\n\t [[{{node sequential_1/dense/MatMul}}]]"
     ]
    }
   ],
   "source": [
    "new_model.predict([x_train[45].reshape(28,28)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
